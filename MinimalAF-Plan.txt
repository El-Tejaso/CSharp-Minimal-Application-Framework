TODO:	
	- 3D and non-immediate mode support
		- 2 parts - mesh loading, shader loading
			- different meshes have different vertex components defined for each vertex. shaders must be different for each different type of mesh. Shaders should therefore be tied to specific vertex types.
			tasks:
				- [done] Change meshes to work with a generic vertex type
				- [done] Allow some way of syncing global uniforms between shaders
				- change shaders to require a generic vertex type in order to work at all. Use reflection to do the Layout(one) = whatever.
					(look at the discussion below abt shaders, implement whatever is good)
		
		-> 3D mesh rendering support
			- shader requires certain vertex attributes to work.
			should people be writing their own OpenGL shaders? wtf?
			-> YES
		-> Users will need to tightly couple their shaders with their vertices
		-> BUt if users are defining their own verts, then will we need to switch back and forth between shaders and stuff?
		-> How would we be switching back and forth between shaders?
		-> what about compute shaders? what about all the other things u can do with OpenGL? how much flexibility should we actually give people?
		-> Whole point of a framework - reduce flexibility.
		-> OK, so what we should do is:
			-> A mesh renderer. It takes mesh data + a shader. we will be switching between the MinimalAF internal shader to render our own stuff, and then to the mesh renderer's shader before we render that. Copying unity a bit there
			-> So they will have to write their own shaders?
			-> I think I will have to write a bunch of shaders and find the patterns.
		-> I could make it easier to write shaders by injecting a bunch of code into the shader. People could even choose what code they want. If they write something like {{preamble}} after #version, I could do a substitution with all the boilerplate code.
		Then I could add something like {{lighting_helpers}} into the shader and substitute in all the lighting related functions.
		-> 
		

		-* Fix framebuffer. I
		-* texture buffer resizing [Texture.cs ln 68]
			-* currently created with new() each time
			
	
	-* Analyse allocations, we are getting a lot of GC pauses
		- only in debug mode though, and not in release
	
	-* PushDepth, something like pushmatrix but we're settign the 2D depth temporarily. it's like Z-Index in HTML but actually useful
	
	-* Try to understand how the depth is working, and why it doesnt work for 
	numbers greater than 1. Near far clipping planes?
	
	-* figure out what we should do with PushMatrix, now that we have other ways of setting the matrix wich will probably be better
	
Backlog: 
	- feature: Modify public properties during test with test harness
		
	- fix: implement Disposable for Audiosource and possibly other classes
		since they are now pooled
			
	- test: Add unit tests for renderbuffer
		-* find rare memory corruption bug that may now be fixed
	
	- make stencil stack-based somehow
	
	
Distant future:
	- feature: Some way to see the element tree in the test harness
		- Will need to be root-node-state based and done in AfterRender. Also figure out some way to move debug overlay to here as well	
		
	- feature: Add dynamic compilation (in general, not just test harness)
		-* find that ms doc page about c# dynamic compilation
		
	- fix: Why is it taking up so much memory in RAM. reduce this
	
	